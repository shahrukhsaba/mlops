# Heart Disease Prediction - MLOps Assignment

[![CI/CD Pipeline](https://github.com/shahrukhsaba/mlops/actions/workflows/ci-cd.yml/badge.svg)](https://github.com/shahrukhsaba/mlops/actions)
[![Python 3.10](https://img.shields.io/badge/python-3.10-blue.svg)](https://www.python.org/downloads/)
[![Docker](https://img.shields.io/badge/docker-ready-blue.svg)](https://www.docker.com/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

**BITS Pilani - MLOps Assignment (S1-25_AIMLCZG523)**

A production-ready MLOps pipeline for predicting heart disease risk using the UCI Heart Disease dataset. This project demonstrates end-to-end ML model development, CI/CD, containerization, and cloud deployment.

---

## üöÄ Quick Start - Run the Complete Project

```bash
# Step 1: Clone and navigate to the project
git clone https://github.com/shahrukhsaba/mlops.git
cd mlops

# Step 2: Install dependencies
pip install -r requirements.txt

# Step 3: Download and prepare data
python scripts/download_data.py

# Step 4: Train the model
python scripts/train_and_save_locally.py

# Step 5: Build Docker image
docker build -t heart-disease-api:latest .

# Step 6: Run Docker container
docker run -d --name heart-disease-api -p 8000:8000 heart-disease-api:latest

# Step 7: Test the API
curl http://localhost:8000/health
curl -X POST "http://localhost:8000/predict?age=63&sex=1&cp=3&trestbps=145&chol=233&fbs=1&restecg=0&thalach=150&exang=0&oldpeak=2.3&slope=0&ca=0&thal=1"

# Step 8: Open API documentation
open http://localhost:8000/docs
```

---

## üìã Table of Contents

- [Quick Start](#-quick-start---run-the-complete-project)
- [Overview](#-overview)
- [Features](#-features)
- [Project Structure](#-project-structure)
- [Detailed Execution Steps](#-detailed-execution-steps)
- [Data Acquisition](#-data-acquisition)
- [Model Training](#-model-training)
- [API Usage](#-api-usage)
- [Docker Deployment](#-docker-deployment)
- [Kubernetes Deployment](#-kubernetes-deployment)
- [CI/CD Pipeline](#-cicd-pipeline)
- [Monitoring](#-monitoring)
- [Testing](#-testing)
- [MLflow Experiment Tracking](#-mlflow-experiment-tracking)

---

## üéØ Overview

This project builds a machine learning classifier to predict heart disease risk based on patient health data. It includes:

- **Data Pipeline**: Automated data ingestion, validation, and preprocessing
- **Model Training**: Logistic Regression and Random Forest with hyperparameter tuning
- **Experiment Tracking**: MLflow integration for logging parameters, metrics, and artifacts
- **API Serving**: FastAPI-based prediction service
- **Containerization**: Docker image for portable deployment
- **Orchestration**: Kubernetes manifests for production deployment
- **CI/CD**: GitHub Actions workflow for automated testing and deployment
- **Monitoring**: Prometheus metrics and logging

---

## ‚ú® Features

| Feature | Description |
|---------|-------------|
| üìä EDA | Comprehensive exploratory data analysis with visualizations |
| üîß Feature Engineering | Automated feature creation and preprocessing pipeline |
| ü§ñ Multiple Models | Logistic Regression & Random Forest with GridSearchCV |
| üìà Experiment Tracking | MLflow logging of parameters, metrics, and artifacts |
| üß™ Testing | Unit and integration tests with pytest |
| üê≥ Docker | Containerized API for portable deployment |
| ‚ò∏Ô∏è Kubernetes | Deployment manifests with HPA and health checks |
| üîÑ CI/CD | GitHub Actions for automated pipeline |
| üì° Monitoring | Prometheus metrics and structured logging |

---

## üìÅ Project Structure

```
heart-disease-mlops/
‚îú‚îÄ‚îÄ .github/
‚îÇ   ‚îî‚îÄ‚îÄ workflows/
‚îÇ       ‚îî‚îÄ‚îÄ ci-cd.yml              # GitHub Actions CI/CD pipeline
‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îú‚îÄ‚îÄ app.py                     # FastAPI application
‚îÇ   ‚îú‚îÄ‚îÄ predictor.py               # Prediction logic
‚îÇ   ‚îú‚îÄ‚îÄ schemas.py                 # Pydantic schemas
‚îÇ   ‚îú‚îÄ‚îÄ middleware/                # API middleware
‚îÇ   ‚îî‚îÄ‚îÄ monitoring/                # Prometheus metrics
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/                       # Raw data files
‚îÇ   ‚îî‚îÄ‚îÄ processed/                 # Cleaned data
‚îú‚îÄ‚îÄ k8s/
‚îÇ   ‚îú‚îÄ‚îÄ deployment.yaml            # Kubernetes deployment
‚îÇ   ‚îú‚îÄ‚îÄ configmap.yaml             # Configuration
‚îÇ   ‚îú‚îÄ‚îÄ ingress.yaml               # Ingress rules
‚îÇ   ‚îî‚îÄ‚îÄ namespace.yaml             # Namespace definition
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îî‚îÄ‚îÄ production/                # Production model artifacts
‚îú‚îÄ‚îÄ monitoring/
‚îÇ   ‚îú‚îÄ‚îÄ prometheus/                # Prometheus configuration
‚îÇ   ‚îî‚îÄ‚îÄ grafana/                   # Grafana dashboards
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îú‚îÄ‚îÄ 01_eda.ipynb               # Exploratory Data Analysis
‚îÇ   ‚îú‚îÄ‚îÄ 02_feature_engineering.ipynb
‚îÇ   ‚îî‚îÄ‚îÄ 03_mlflow_experiments.ipynb
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ download_data.py           # Data download script
‚îÇ   ‚îî‚îÄ‚îÄ train_and_save_locally.py  # Local training script
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ data/                      # Data loading and preprocessing
‚îÇ   ‚îú‚îÄ‚îÄ features/                  # Feature engineering
‚îÇ   ‚îú‚îÄ‚îÄ models/                    # Model training
‚îÇ   ‚îú‚îÄ‚îÄ monitoring/                # Drift detection
‚îÇ   ‚îî‚îÄ‚îÄ tracking/                  # MLflow utilities
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ unit/                      # Unit tests
‚îÇ   ‚îî‚îÄ‚îÄ integration/               # Integration tests
‚îú‚îÄ‚îÄ Dockerfile                     # Docker image definition
‚îú‚îÄ‚îÄ docker-compose.yml             # Multi-container setup
‚îú‚îÄ‚îÄ requirements.txt               # Python dependencies
‚îî‚îÄ‚îÄ README.md                      # This file
```

---

## üìù Detailed Execution Steps

### Prerequisites

- Python 3.9+ or 3.10+
- Docker Desktop (for containerization)
- Git

### Step 1: Clone and Setup

```bash
# Clone the repository
git clone https://github.com/shahrukhsaba/mlops.git
cd mlops

# Create virtual environment (optional but recommended)
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### Step 2: Download Data

```bash
python scripts/download_data.py
```

**Expected Output:**
```
Dataset download and processing complete!
Final dataset shape: (297, 14)
Target distribution: {0: 160, 1: 137}
```

### Step 3: Train the Model

```bash
python scripts/train_and_save_locally.py
```

**Expected Output:**
```
Training Random Forest model for packaging...
Model saved to models/random_forest/model.pkl
```

### Step 4: Build Docker Image

```bash
docker build -t heart-disease-api:latest .
```

### Step 5: Run Docker Container

```bash
docker run -d --name heart-disease-api -p 8000:8000 heart-disease-api:latest
```

### Step 6: Test the API

```bash
# Health check
curl http://localhost:8000/health

# Make a prediction
curl -X POST "http://localhost:8000/predict?age=63&sex=1&cp=3&trestbps=145&chol=233&fbs=1&restecg=0&thalach=150&exang=0&oldpeak=2.3&slope=0&ca=0&thal=1"
```

**Expected Response:**
```json
{
  "prediction": 0,
  "confidence": 0.2737,
  "risk_level": "Low",
  "probability_no_disease": 0.7263,
  "probability_disease": 0.2737,
  "processing_time_ms": 17.38
}
```

### Step 7: View API Documentation

Open in browser: http://localhost:8000/docs

### Step 8: Stop Container (when done)

```bash
docker stop heart-disease-api
docker rm heart-disease-api
```

---

## üì• Data Acquisition

### Download Dataset

The UCI Heart Disease dataset can be downloaded automatically:

```bash
python scripts/download_data.py
```

This script will:
- Download data from UCI Machine Learning Repository
- Clean and preprocess the data
- Save to `data/processed/heart_disease_clean.csv`
- Generate metadata in `data/processed/metadata.json`

### Dataset Description

| Feature | Description | Type |
|---------|-------------|------|
| age | Age in years | Numerical |
| sex | Sex (1=male, 0=female) | Binary |
| cp | Chest pain type (0-3) | Categorical |
| trestbps | Resting blood pressure (mm Hg) | Numerical |
| chol | Serum cholesterol (mg/dl) | Numerical |
| fbs | Fasting blood sugar > 120 mg/dl | Binary |
| restecg | Resting ECG results (0-2) | Categorical |
| thalach | Maximum heart rate achieved | Numerical |
| exang | Exercise induced angina | Binary |
| oldpeak | ST depression induced by exercise | Numerical |
| slope | Slope of peak exercise ST segment | Categorical |
| ca | Number of major vessels (0-3) | Numerical |
| thal | Thalassemia type | Categorical |
| target | Heart disease presence (0/1) | Binary |

---

## üéì Model Training

### Train Models

Train both Logistic Regression and Random Forest models:

```bash
python src/models/train_models.py
```

This will:
1. Load and preprocess the data
2. Train Logistic Regression with hyperparameter tuning
3. Train Random Forest with hyperparameter tuning
4. Log experiments to MLflow
5. Save the best model to `models/production/`

### View MLflow Experiments

```bash
mlflow ui --port 5000
```

Open http://localhost:5000 to view experiment tracking.

---

## üåê API Usage

### Run API Locally

```bash
uvicorn api.app:app --reload --host 0.0.0.0 --port 8000
```

### API Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/health` | GET | Health check |
| `/predict` | POST | Make prediction |
| `/docs` | GET | Swagger documentation |

### Example Request

```bash
curl -X POST "http://localhost:8000/predict?age=63&sex=1&cp=3&trestbps=145&chol=233&fbs=1&restecg=0&thalach=150&exang=0&oldpeak=2.3&slope=0&ca=0&thal=1"
```

### Example Response

```json
{
  "prediction": 1,
  "confidence": 0.85
}
```

### Interactive Documentation

Open http://localhost:8000/docs for Swagger UI.

---

## üê≥ Docker Deployment

### Build Docker Image

```bash
docker build -t heart-disease-api:latest .
```

### Run Container

```bash
docker run -p 8000:8000 heart-disease-api:latest
```

### Using Docker Compose

```bash
docker-compose up -d
```

This starts both the API and MLflow server.

### Test Container

```bash
# Health check
curl http://localhost:8000/health

# Prediction
curl -X POST "http://localhost:8000/predict?age=63&sex=1&cp=3&trestbps=145&chol=233&fbs=1&restecg=0&thalach=150&exang=0&oldpeak=2.3&slope=0&ca=0&thal=1"
```

---

## ‚ò∏Ô∏è Kubernetes Deployment

### Prerequisites

- Minikube or a Kubernetes cluster
- kubectl configured

### Deploy to Minikube

```bash
# Start Minikube
minikube start

# Use Minikube's Docker daemon
eval $(minikube docker-env)

# Build image in Minikube
docker build -t heart-disease-api:latest .

# Apply Kubernetes manifests
kubectl apply -f k8s/namespace.yaml
kubectl apply -f k8s/configmap.yaml
kubectl apply -f k8s/deployment.yaml
kubectl apply -f k8s/ingress.yaml

# Get service URL
minikube service heart-disease-api --url
```

### Verify Deployment

```bash
# Check pods
kubectl get pods

# Check services
kubectl get svc

# View logs
kubectl logs -l app=heart-disease-api
```

---

## üîÑ CI/CD Pipeline

The GitHub Actions workflow (`.github/workflows/ci-cd.yml`) includes:

1. **Lint**: Code quality checks with flake8, black, isort
2. **Test**: Unit tests with pytest and coverage
3. **Train**: Model training and artifact generation
4. **Docker**: Build and test Docker image
5. **Integration**: API integration tests
6. **Security**: Bandit and safety vulnerability scans

### Trigger Pipeline

Push to `main` or `develop` branch, or open a pull request.

### View Results

Check the Actions tab in your GitHub repository.

---

## üìä Monitoring

### Prometheus Metrics

The API exposes metrics at `/metrics`:

- `predictions_total`: Total predictions by class
- `prediction_confidence`: Confidence score distribution
- `prediction_latency_seconds`: Prediction latency
- `api_requests_total`: Total API requests

### Start Monitoring Stack

```bash
cd monitoring
docker-compose -f docker-compose-monitoring.yml up -d
```

### Access Dashboards

- Prometheus: http://localhost:9090
- Grafana: http://localhost:3000

### Logs

API logs are written to `logs/api.log`.

---

## üß™ Testing

### Run All Tests

```bash
pytest tests/ -v
```

### Run Unit Tests

```bash
pytest tests/unit/ -v
```

### Run Integration Tests

```bash
# Start the API first
uvicorn api.app:app --port 8000 &

# Run integration tests
pytest tests/integration/ -v
```

### Test Coverage

```bash
pytest tests/ --cov=src --cov=api --cov-report=html
```

---

## üìà MLflow Experiment Tracking

### Features Tracked

- **Parameters**: Hyperparameters, model configuration
- **Metrics**: Accuracy, Precision, Recall, F1, ROC-AUC
- **Artifacts**: Model files, preprocessor, plots

### Start MLflow UI

```bash
mlflow ui --port 5000
```

### Compare Experiments

View and compare runs at http://localhost:5000.

---

## üìù Model Performance

| Model | Accuracy | Precision | Recall | F1-Score | ROC-AUC |
|-------|----------|-----------|--------|----------|---------|
| Logistic Regression | 80.00% | 83.33% | 71.43% | 76.92% | **92.86%** |
| Random Forest | **81.67%** | 81.48% | **78.57%** | **80.00%** | 91.52% |

*Note: Logistic Regression achieved higher ROC-AUC while Random Forest had better overall accuracy.*

---

## üîí Security

- Input validation with Pydantic schemas
- Health checks for container orchestration
- Dependency vulnerability scanning with safety
- Code security analysis with Bandit

---

## üìÑ License

This project is licensed under the MIT License.

---

## üë• Authors

- **Sk Shahrukh Saba** - MLOps Assignment

---

## üôè Acknowledgments

- UCI Machine Learning Repository for the Heart Disease dataset
- BITS Pilani for the MLOps course

